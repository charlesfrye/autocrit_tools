{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import autocrit\n",
    "import autocrit.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortdir(obj):\n",
    "    return  [elem for elem in dir(obj) if not elem.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`autocrit` has two inter-mixed functions:\n",
    "1. Provide implementations of critical point-finding algorithms for neural networks in `autograd`.\n",
    "2. Allow for saving and reproduction of critical point-finding experiments.\n",
    "\n",
    "As such, there are often two APIs: one aimed at easing goal 1, the other aimed at easing goal 2.\n",
    "\n",
    "When fiddling around in a notebook, the first type of API is preferred -- it's easy for humans to work with.\n",
    "When programmatically executing experiments, the latter type is preferred -- it's easy to write programs that use it\n",
    "\n",
    "Programmatic execution of reproducible experiments is supported by the scripts in the `scripts/` folder in `autocrit_tools/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top-level namespace\n",
    "\n",
    "Modules plus convenient access to main classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_lvl = shortdir(autocrit)\n",
    "\n",
    "top_lvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the cell to see the docstrings for all of the classes (and their methods) and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(autocrit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the classes that are most useful for finding the critical points of simple neural network loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_classes = [elem for elem in shortdir(autocrit) if elem[0].isupper()]\n",
    "\n",
    "main_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `FastNewton{MR, TR}` and `GradientNormMinimizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the critical point-finding algorithms.\n",
    "\n",
    "Each is a sub-class of `autocrit.finders.base.Finder`,\n",
    "an abstract base class that handles basics like\n",
    "logging.\n",
    "\n",
    "See the help for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACHTUNG: **The functions optimized by the `Finder` need to take _column vectors_ as inputs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issubclass(autocrit.FastNewtonMR, autocrit.finders.base.Finder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autocrit.finders.base.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(autocrit.finders.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `FullyConnectedNetwork`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the easiest way to specify a simple neural network.\n",
    "\n",
    "Each layer must be fully connected and have the same hyperparameters (`has_biases`, `nonlinearity_str`).\n",
    "\n",
    "For more general neural networks, see `autocrit.nn.networks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(autocrit.FullyConnectedNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CritFinderExperiment` and `OptimizationExperiment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are `Experiments`, which know how to use `Finder`s or `Optimizer`s and save their results to files.\n",
    "\n",
    "They also know how to both convert an `Experiment` to a `.json` file and how to recreate an `Experiment` from its `.json` file.\n",
    "For more on how these are used, see the `scripts/` in `autocrit_tools`.\n",
    "\n",
    "This functionality is only important for running lots of reproducible experiments\n",
    "and tracking the results.\n",
    "These classes are unnecessary for doing simple things\n",
    "(for example, they aren't used in the tests of the `Optimizer`s or `Finder`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issubclass(autocrit.CritFinderExperiment, autocrit.experiments.Experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autocrit.experiments.Experiment.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last bit you'll need is a way to define optimizers,\n",
    "since optimization trajectories are often used as \"seeds\"\n",
    "for critical point-finding methods.\n",
    "\n",
    "See `optimizers` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [elem for elem in shortdir(autocrit) if not elem[0].isupper()]\n",
    "\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `defaults` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared default values of all of the major numerical parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortdir(autocrit.defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below for (terse) definitions.\n",
    "\n",
    "They should point you to the place where the values are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autocrit.defaults??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where `CritFinderExperiment` and `OptimizationExperiment` are defined. See discussion above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn` is the library for building `n`eural `n`etworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortdir(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has somewhat the same style as the `Sequential` API in `pytorch`:\n",
    "networks are made of `Layer`s, and the output of one `Layer` is the input to the next.\n",
    "\n",
    "`Layer`s are defined inside `nn.layers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.layers.Layer.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aribtrary non-parameterized transformations are supported by a `LambdaLayer`,\n",
    "but `Network`s containing a `LambdaLayer` can't be rebuilt,\n",
    "so they're incompatible with `Experiment`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.layers.LambdaLayer.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Network`s are built from `Layer`s based on the `layer_spec` argument to a call to `Network()`. `layer_spec` can either be\n",
    "\n",
    "1. A literal list of `Layer`s\n",
    "2. A list of dictionaries, whose keys are `\"type\"` and `\"params\"`. `\"type\"` is the name of the layer type, as below. `\"params\"` is a dictionary used as the `kwargs` to the construction of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.layers._LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a fully connected layer (`FCLayer`)\n",
    "with four output nodes would be specified by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"type\": \"fc\",\n",
    " \"params\": {\"out_nodes\": 4}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the docstrings for `__init__` methods for details about the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.layers.FCLayer.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building networks by hand, it's usually easier to just build them directly with the `Layer` constructors.\n",
    "This API is intended for use with rebuilding networks from their `.json` representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data must be provided to the network as\n",
    "a tuple of inputs and targets,\n",
    "and is stored as an attribute\n",
    "`network.data`,\n",
    "which has attributes `data.x` and `data.y`\n",
    "for inputs and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is calculated by a method called `.loss`,\n",
    "which calculates the loss on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.networks.Network.loss??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do stochastic gradient descent,\n",
    "you need to use `.loss_on_random_batch`.\n",
    "\n",
    "Note that if the `batch_size` is not specified during creation of the network,\n",
    "then it defaults to the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `optimizers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FirstOrderOptimizer`s (the only kind I ever got around to implementing)\n",
    "use an `autograd` function `f` or optional `grad_f` calculator\n",
    "to do first-order optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autocrit.optimizers.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autocrit.optimizers.FirstOrderOptimizer.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key method defined in the base class is `.run`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocrit.optimizers.FirstOrderOptimizer.run??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It punts on implementation of the algorithm to the concrete class,\n",
    "which must implement a `.update`,\n",
    "as in `GradientDescentOptimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocrit.optimizers.GradientDescentOptimizer??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `finders` and `gradnormin`/`newtons`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`finders` contains the implementations of the `Finder` classes,\n",
    "inside the submodules\n",
    "`gradnormmin` and `newtons`,\n",
    "which are also accessible from the top-level namespace.\n",
    "\n",
    "The various Newton methods are defined by over-riding methods of a base class,\n",
    "`NewtonMethod`,\n",
    "with the inheritance structure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "            NewtonBTLS - NewtonMR - FastNewtonMR\n",
    "        /\n",
    "NewtonMethod \n",
    "        \\\n",
    "            NewtonPI  - NewtonTR - FastNewtonTR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BTLS` stands for \"back-tracking line search\" and `PI` stands for \"pseudo-inverse\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docs for `NewtonMethod` explain this well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autocrit.finders.newtons.NewtonMethod.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gradnormmin.GradientNormMinimizer` makes use of the `FirstOrderMinimizer` classes,\n",
    "but applies them to the squared gradient norm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
